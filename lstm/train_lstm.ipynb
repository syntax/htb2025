{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from CSV...\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load Data ---\n",
    "CSV_FILE        = \"crypto_price_data.csv\"\n",
    "SAVE_MODEL_PATH = \"mvp_lstm_model.h5\"\n",
    "SAVE_SCALER_PATH = \"mvp_scaler.pkl\"\n",
    "\n",
    "print(\"Loading data from CSV...\")\n",
    "df = pd.read_csv(CSV_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Sort by Ticker, Date ---\n",
    "df.sort_values(by=[\"Ticker\", \"Date\"], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape after excluding last 60 days: (99264, 215)\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Exclude Last 60 Days Per Ticker ---\n",
    "LOOK_BACK = 60\n",
    "df_list = []\n",
    "for ticker in df[\"Ticker\"].unique():\n",
    "    sub = df[df[\"Ticker\"] == ticker].copy()\n",
    "    # If there's not enough data to drop 60 days, skip ticker\n",
    "    if len(sub) <= LOOK_BACK:\n",
    "        print(f\"Skipping {ticker}: Not enough data to remove last 60 days.\")\n",
    "        continue\n",
    "    \n",
    "    # Drop the last 60 rows for this ticker\n",
    "    sub = sub.iloc[:-LOOK_BACK]\n",
    "    df_list.append(sub)\n",
    "\n",
    "# Merge back\n",
    "if not df_list:\n",
    "    raise ValueError(\"No data available after excluding the last 60 days.\")\n",
    "\n",
    "df_train = pd.concat(df_list).reset_index(drop=True)\n",
    "print(\"Data shape after excluding last 60 days:\", df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scalers saved to mvp_scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Scale Data Per Ticker ---\n",
    "scaler_dict = {}\n",
    "df_scaled_list = []\n",
    "\n",
    "for ticker in df_train[\"Ticker\"].unique():\n",
    "    sub = df_train[df_train[\"Ticker\"] == ticker].copy()\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    sub[\"CloseScaled\"] = scaler.fit_transform(sub[[\"Close\"]])\n",
    "    scaler_dict[ticker] = scaler\n",
    "    df_scaled_list.append(sub)\n",
    "\n",
    "df_scaled = pd.concat(df_scaled_list).reset_index(drop=True)\n",
    "\n",
    "# Save the scaler dictionary\n",
    "joblib.dump(scaler_dict, SAVE_SCALER_PATH)\n",
    "print(f\"Scalers saved to {SAVE_SCALER_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating sequences...\n",
      "Full dataset: X.shape=(94580, 60, 1), y.shape=(94580, 3)\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Create Sequences for Multi-step Prediction ---\n",
    "PREDICTION_HORIZONS = [1, 7, 30]  # Next-day, next-week, next-month\n",
    "\n",
    "def create_sequences(df, look_back=LOOK_BACK, horizons=PREDICTION_HORIZONS):\n",
    "    X_list, y_list, tickers_list = [], [], []\n",
    "    \n",
    "    for ticker in df[\"Ticker\"].unique():\n",
    "        sub = df[df[\"Ticker\"] == ticker].copy().reset_index(drop=True)\n",
    "        close_scaled = sub[\"CloseScaled\"].values\n",
    "        \n",
    "        # Generate sequences\n",
    "        for i in range(len(sub) - look_back - max(horizons)):\n",
    "            X_seq = close_scaled[i : i + look_back].reshape(-1, 1)  # shape (60, 1)\n",
    "            # Multi-step targets\n",
    "            y_seq = [close_scaled[i + look_back + h - 1] for h in horizons]\n",
    "            \n",
    "            X_list.append(X_seq)\n",
    "            y_list.append(y_seq)\n",
    "            tickers_list.append(ticker)\n",
    "    \n",
    "    X_arr = np.array(X_list)\n",
    "    y_arr = np.array(y_list)\n",
    "    return X_arr, y_arr, tickers_list\n",
    "\n",
    "print(\"Creating sequences...\")\n",
    "X, y, tickers_seq = create_sequences(df_scaled)\n",
    "\n",
    "print(f\"Full dataset: X.shape={X.shape}, y.shape={y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: X_train=(75664, 60, 1), y_train=(75664, 3)\n",
      "Val size: X_val=(18916, 60, 1), y_val=(18916, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 6. Train/Validation Split (80/20) ---\n",
    "# We'll do a simple random split at the sequence level.\n",
    "# Time-series best practice is to keep chronological order,\n",
    "# but since the last 60 days are already excluded, we can do a simple ratio.\n",
    "\n",
    "split_index = int(len(X) * 0.8)\n",
    "X_train, X_val = X[:split_index], X[split_index:]\n",
    "y_train, y_val = y[:split_index], y[split_index:]\n",
    "\n",
    "print(f\"Train size: X_train={X_train.shape}, y_train={y_train.shape}\")\n",
    "print(f\"Val size: X_val={X_val.shape}, y_val={y_val.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacksmith/Desktop/ltsm/lstm_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m16,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,115</span> (195.76 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m50,115\u001b[0m (195.76 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,115</span> (195.76 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m50,115\u001b[0m (195.76 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 7. Build LSTM Model ---\n",
    "model = Sequential([\n",
    "    LSTM(64, return_sequences=True, input_shape=(LOOK_BACK, 1)),\n",
    "    Dropout(0.2),\n",
    "    LSTM(64, return_sequences=False),\n",
    "    Dropout(0.2),\n",
    "    Dense(len(PREDICTION_HORIZONS))  # 3 outputs: EOD, EOW, EOM\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Epoch 1/10\n",
      "\u001b[1m2365/2365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 21ms/step - loss: 0.0116 - val_loss: 0.0032\n",
      "Epoch 2/10\n",
      "\u001b[1m2365/2365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 21ms/step - loss: 0.0052 - val_loss: 0.0029\n",
      "Epoch 3/10\n",
      "\u001b[1m2365/2365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 21ms/step - loss: 0.0048 - val_loss: 0.0028\n",
      "Epoch 4/10\n",
      "\u001b[1m2365/2365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 21ms/step - loss: 0.0047 - val_loss: 0.0028\n",
      "Epoch 5/10\n",
      "\u001b[1m2365/2365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 21ms/step - loss: 0.0046 - val_loss: 0.0027\n",
      "Epoch 6/10\n",
      "\u001b[1m2365/2365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 21ms/step - loss: 0.0045 - val_loss: 0.0026\n",
      "Epoch 7/10\n",
      "\u001b[1m2365/2365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 21ms/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 8/10\n",
      "\u001b[1m2365/2365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 21ms/step - loss: 0.0044 - val_loss: 0.0025\n",
      "Epoch 9/10\n",
      "\u001b[1m2365/2365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 21ms/step - loss: 0.0043 - val_loss: 0.0025\n",
      "Epoch 10/10\n",
      "\u001b[1m2365/2365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 21ms/step - loss: 0.0043 - val_loss: 0.0026\n"
     ]
    }
   ],
   "source": [
    "# --- 8. Train Model ---\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "print(\"Training model...\")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False  # keep sequence order\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to mvp_lstm_model.h5\n"
     ]
    }
   ],
   "source": [
    "# --- 9. Save Model ---\n",
    "model.save(SAVE_MODEL_PATH)\n",
    "print(f\"Model saved to {SAVE_MODEL_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lstm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
